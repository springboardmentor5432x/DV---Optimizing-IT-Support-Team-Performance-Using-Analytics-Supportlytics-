{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ticket Analytics Milestones Notebook\n",
        "\n",
        "This notebook orchestrates Milestone 1 cleaning and feature engineering.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef49b9de",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Ensure project root (containing `src/`) is on sys.path\n",
        "CWD = os.path.abspath(os.getcwd())\n",
        "BASE_DIR = CWD\n",
        "for candidate in [CWD, os.path.dirname(CWD)]:\n",
        "    if os.path.isdir(os.path.join(candidate, \"src\")):\n",
        "        BASE_DIR = candidate\n",
        "        if candidate not in sys.path:\n",
        "            sys.path.append(candidate)\n",
        "        break\n",
        "\n",
        "from src.schema import detect_schema\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "# Paths relative to detected project root\n",
        "RAW_PATH = os.path.join(BASE_DIR, 'data', 'raw', 'customer_support_tickets.csv')\n",
        "PROCESSED_DIR = os.path.join(BASE_DIR, 'data', 'processed')\n",
        "FIG_DIR = os.path.join(BASE_DIR, 'outputs', 'figures')\n",
        "REPORT_DIR = os.path.join(BASE_DIR, 'reports')\n",
        "\n",
        "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
        "os.makedirs(FIG_DIR, exist_ok=True)\n",
        "os.makedirs(REPORT_DIR, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Milestone 1 / Module 1: Initialization & Dataset Setup\n",
        "\n",
        "Load the raw CSV, inspect schema/dtypes/missingness, and detect canonical column names using src.schema.detect_schema.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load raw dataset\n",
        "df_raw = pd.read_csv(RAW_PATH)\n",
        "print('Raw shape:', df_raw.shape)\n",
        "print('Columns:', df_raw.columns.tolist())\n",
        "print('\\nDtypes:\\n', df_raw.dtypes)\n",
        "print('\\nMissing (top 20):\\n', df_raw.isna().sum().sort_values(ascending=False).head(20))\n",
        "\n",
        "# Detect logical columns\n",
        "schema = detect_schema(df_raw)\n",
        "print('\\nDetected schema mapping:')\n",
        "for k, v in schema.as_dict().items():\n",
        "    print(f'- {k}: {v}')\n",
        "\n",
        "# Initial ticket distributions (type, priority, category)\n",
        "def save_bar(series, title, filename, top_n=15):\n",
        "    s = series.dropna().astype(str).str.strip()\n",
        "    vc = s.value_counts().head(top_n)\n",
        "    plt.figure()\n",
        "    vc.sort_values().plot(kind='bar')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Value')\n",
        "    plt.ylabel('Count')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(FIG_DIR, filename), dpi=200)\n",
        "    plt.close()\n",
        "\n",
        "if schema.type:\n",
        "    save_bar(df_raw[schema.type], 'Ticket Distribution by Type', 'm1_type_distribution.png')\n",
        "if schema.priority:\n",
        "    save_bar(df_raw[schema.priority], 'Ticket Distribution by Priority', 'm1_priority_distribution.png')\n",
        "if schema.category:\n",
        "    save_bar(df_raw[schema.category], 'Ticket Distribution by Category', 'm1_category_distribution.png')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Milestone 1 / Module 2: Cleaning & Feature Engineering\n",
        "\n",
        "Run the robust cleaning + feature engineering pipeline from src.milestone1_pipeline to produce processed datasets and documentation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run milestone 1 pipeline (module executes on import)\n",
        "import src.milestone1_pipeline  # noqa: F401\n",
        "\n",
        "# Load features dataset for downstream modules\n",
        "features_path = os.path.join(PROCESSED_DIR, 'tickets_features.csv')\n",
        "df_feat = pd.read_csv(features_path)\n",
        "schema_feat = detect_schema(df_feat)\n",
        "print('Features shape:', df_feat.shape)\n",
        "print('Schema on features:')\n",
        "for k, v in schema_feat.as_dict().items():\n",
        "    print(f'- {k}: {v}')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
